# ZDLang Agent - Intelligent Multi-Tool Agent System

A sophisticated intelligent agent system built with LangChain that automatically routes between local LLM services and MCP (Model Context Protocol) weather services. The system provides seamless integration between conversational AI and weather data retrieval through an intuitive web interface.

## ğŸŒŸ Features

- **Intelligent Routing**: Automatically detects user intent and routes to appropriate tools
- **Dual-Language Support**: Supports both English and Chinese queries
- **Weather Integration**: Real-time weather data via MCP weather service
- **Local LLM**: Powered by deepseek-r1-7b model through Ollama
- **Web Interface**: Clean, modern web UI for easy interaction
- **RESTful API**: Complete API endpoints for programmatic access
- **Tool Transparency**: Shows which tools are being used during processing

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web Frontend  â”‚â”€â”€â”€â”€â”‚  Flask Web API  â”‚â”€â”€â”€â”€â”‚  SimpleAgent    â”‚
â”‚   (index.html)  â”‚    â”‚    (app.py)     â”‚    â”‚   (agent.py)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚
                                                       â–¼
                                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                              â”‚ Intent Router   â”‚
                                              â”‚ (Keyword Match) â”‚
                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â–¼                  â–¼                  â–¼
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚  Weather Tool   â”‚ â”‚   Chat Tool     â”‚ â”‚  External APIs  â”‚
                           â”‚(weather_tool.py)â”‚ â”‚ (chat_tool.py)  â”‚ â”‚                 â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚                  â”‚
                                    â–¼                  â–¼
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚ MCP Weather API â”‚ â”‚  Ollama LLM     â”‚
                           â”‚ (localhost:8081)â”‚ â”‚(localhost:11434)â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- Ollama with deepseek-r1-7b model
- MCP Weather Service running on port 8081
- Node.js (for MCP service)

### Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd zdlang-agent
   ```

2. **Install Python dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Start Ollama service**
   ```bash
   ollama serve
   ollama pull deepseek-r1:7b
   ```

4. **Start MCP Weather Service**
   ```bash
   # In a separate terminal
   cd mcp-weather-service
   npm start
   ```

5. **Run the application**
   ```bash
   python app.py
   ```

6. **Access the web interface**
   Open your browser and navigate to: `http://localhost:5001`

## ğŸ“‹ API Endpoints

### Health Check
```http
GET /health
```
Returns system health status.

### Get Available Tools
```http
GET /api/tools
```
Returns list of available tools with descriptions.

### Query Processing
```http
POST /api/query
Content-Type: application/json

{
  "query": "What's the weather in Beijing?"
}
```

**Response:**
```json
{
  "success": true,
  "result": "Beijing current weather: overcast, temperature 28Â°C, southeast wind â‰¤3 level, humidity 78%",
  "intermediate_steps": [["weather", "Weather data retrieved successfully"]],
  "query": "What's the weather in Beijing?"
}
```

## ğŸ› ï¸ Project Structure

```
zdlang-agent/
â”œâ”€â”€ app.py                 # Flask web server and API endpoints
â”œâ”€â”€ agent.py              # SimpleAgent implementation
â”œâ”€â”€ config.py             # Configuration settings
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ weather_tool.py   # Weather query tool
â”‚   â””â”€â”€ chat_tool.py      # General conversation tool
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html        # Web interface
â””â”€â”€ core/
    â””â”€â”€ __init__.py
```

## ğŸ”§ Configuration

Edit `config.py` to customize:

- **Flask Settings**: Port, debug mode, host configuration
- **Ollama Settings**: Model name, API endpoint
- **MCP Settings**: Weather service URL and timeout
- **Agent Settings**: Max iterations, execution timeout

```python
# Example configuration
FLASK_CONFIG = {
    'host': '0.0.0.0',
    'port': 5001,
    'debug': True
}

OLLAMA_CONFIG = {
    'base_url': 'http://localhost:11434',
    'model': 'deepseek-r1:7b'
}
```

## ğŸ’¡ Usage Examples

### Weather Queries
- "What's the weather in Shanghai?"
- "ä¸Šæµ·å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"
- "Tell me about Beijing's weather"
- "åŒ—äº¬ç°åœ¨ä¸‹é›¨å—ï¼Ÿ"

### General Conversation
- "Tell me a joke"
- "What is artificial intelligence?"
- "Explain quantum computing"
- "How do neural networks work?"

## ğŸ” How It Works

1. **Intent Recognition**: The SimpleAgent analyzes user queries using keyword matching
2. **Tool Selection**: Based on detected intent, routes to appropriate tool:
   - Weather keywords â†’ Weather Tool â†’ MCP Weather API
   - Other queries â†’ Chat Tool â†’ Ollama LLM
3. **Response Processing**: Tools process requests and return formatted responses
4. **Result Delivery**: Final results are sent back through the API to the frontend

## ğŸŒ¤ï¸ Weather Tool Features

- **Multi-language Support**: Recognizes weather queries in English and Chinese
- **City Recognition**: Supports major cities in both languages
- **Data Processing**: Directly parses weather API responses for optimal performance
- **Error Handling**: Comprehensive error handling for API failures

**Supported Weather Keywords:**
- English: weather, temperature, rain, sunny, cloudy, wind
- Chinese: å¤©æ°”, æ°”æ¸©, æ¸©åº¦, ä¸‹é›¨, æ™´å¤©, é˜´å¤©, åˆ®é£

## ğŸ’¬ Chat Tool Features

- **LLM Integration**: Powered by deepseek-r1-7b through Ollama
- **Response Cleaning**: Removes internal thinking tags for clean output
- **Error Recovery**: Handles LLM failures gracefully
- **Logging**: Comprehensive logging for debugging

## ğŸ¯ Key Design Decisions

### Why SimpleAgent?
- **Reliability**: Avoids complex ReAct format parsing issues
- **Performance**: Direct keyword matching is faster than LLM-based routing
- **Maintainability**: Easier to debug and extend
- **Predictability**: Consistent behavior across different query types

### Tool Architecture Benefits
- **Modularity**: Easy to add new tools
- **Isolation**: Tool failures don't affect the entire system
- **Flexibility**: Each tool can have its own processing logic
- **Scalability**: Can easily integrate additional external services

## ğŸš¨ Troubleshooting

### Common Issues

1. **Ollama Connection Failed**
   - Ensure Ollama service is running: `ollama serve`
   - Check if model is installed: `ollama list`

2. **MCP Weather Service Unavailable**
   - Verify MCP service is running on port 8081
   - Check network connectivity to weather API

3. **Web Interface Not Loading**
   - Confirm Flask app is running on correct port
   - Check for port conflicts

### Debug Mode
Enable debug logging by setting `debug=True` in `config.py`:

```python
FLASK_CONFIG = {
    'debug': True
}
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature-name`
3. Commit your changes: `git commit -am 'Add feature'`
4. Push to the branch: `git push origin feature-name`
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- **LangChain**: For the agent framework
- **Ollama**: For local LLM serving
- **MCP Protocol**: For weather service integration
- **Flask**: For the web framework

## ğŸ“ Support

For questions or issues:
1. Check the troubleshooting section above
2. Review the logs for error details
3. Open an issue on GitHub with:
   - Error description
   - Steps to reproduce
   - System information
   - Relevant log output

---

**Built with â¤ï¸ using LangChain, Flask, and Ollama** 